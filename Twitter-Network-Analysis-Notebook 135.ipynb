{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f0851",
   "metadata": {},
   "source": [
    "# 1.0 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd60eb04",
   "metadata": {},
   "source": [
    "# 2.0 Authenticating with Twitter's API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7058aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from Twython) (2.25.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, Twython\n",
      "Successfully installed Twython-3.9.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd422936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3f08dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decorator==5.0.9\n",
      "  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: decorator\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.6\n",
      "    Uninstalling decorator-5.0.6:\n",
      "      Successfully uninstalled decorator-5.0.6\n",
      "Successfully installed decorator-5.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc89aa",
   "metadata": {},
   "source": [
    "## 2.1 Enter app info and get auth URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360821",
   "metadata": {},
   "source": [
    "In order to authenticate with Twitter, we'll provide the app details and ask for a one-time authorization URL to authenticate your user with this app.\n",
    "\n",
    "Copy and paste the API key and secret from your Twitter app into a file named keys.txt. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the keys.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load keys.txt\n",
    "GRvkTm3qkMOM8YjyNp3S6xLO4\n",
    "YmHFrSSnC7D1qNUemiDbmtaMvF0saiFzyyW15erffxGCuQyiFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the keys file\n",
    "my_file = open(\"keys.txt\", \"r\")\n",
    "\n",
    "# read the raw data\n",
    "content = my_file.read()\n",
    "\n",
    "# split all lines by  newline character\n",
    "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a7e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authenticate?oauth_token=LPL9XAAAAAABZBP-AAABftrkV8E\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
    "\n",
    "authentication_tokens = twitter.get_authentication_tokens()\n",
    "print(authentication_tokens['auth_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc878",
   "metadata": {},
   "source": [
    "## 2.2 Authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
    "VERIFIER = '3396549'\n",
    "\n",
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authentication_tokens['oauth_token'],\n",
    "                  authentication_tokens['oauth_token_secret'])\n",
    "\n",
    "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d775",
   "metadata": {},
   "source": [
    "## 2.3 Use authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f4db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1486095105811484677,\n",
       " 'id_str': '1486095105811484677',\n",
       " 'name': 'Renato Farias',\n",
       " 'screen_name': 'renatolinsfar',\n",
       " 'location': '',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 9,\n",
       " 'friends_count': 50,\n",
       " 'listed_count': 2,\n",
       " 'created_at': 'Tue Jan 25 21:55:10 +0000 2022',\n",
       " 'favourites_count': 0,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
       " 'statuses_count': 1,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sat Jan 29 01:36:43 +0000 2022',\n",
       "  'id': 1487238244727238656,\n",
       "  'id_str': '1487238244727238656',\n",
       "  'text': 'Ol√°, eu acabei de publicar no Medium uma mat√©ria sobre meu trabalho de An√°lise de Redes usando o dataset ‚ÄúSpotify M‚Ä¶ https://t.co/UsjSkojKUd',\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/UsjSkojKUd',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1487238244727238656',\n",
       "     'display_url': 'twitter.com/i/web/status/1‚Ä¶',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'pt'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'F5F8FA',\n",
       " 'profile_background_image_url': None,\n",
       " 'profile_background_image_url_https': None,\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': True,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'withheld_in_countries': [],\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authorized_tokens['oauth_token'],\n",
    "                  authorized_tokens['oauth_token_secret'])\n",
    "\n",
    "twitter.verify_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5bcec",
   "metadata": {},
   "source": [
    "# 3.0 Twitter API basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35e191",
   "metadata": {},
   "source": [
    "We've already seen one User Object, the one corresponding to the logged-in user, via the call to verify_credentials() above. We can also fetch data for an arbitrary user:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ee657",
   "metadata": {},
   "source": [
    "- Acredito que em nosso projeto, n√£o usaremos essa funcionalidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dafc",
   "metadata": {},
   "source": [
    "# 4.0 Using Twitter's search API to get tweets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7bed0",
   "metadata": {},
   "source": [
    "Twitter's Search API allows you to fetch recent tweets according to a query of keywords, URLs, hashtags, user mentions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3572f",
   "metadata": {},
   "source": [
    "## 4.1 Using a cursor to get more than 100 tweets from a search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebd96c",
   "metadata": {},
   "source": [
    "## Getting some tweets for create some graph test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b975cf",
   "metadata": {},
   "source": [
    "- Explorando os limites da API na captura de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even with count=1000, we still get at most 100 tweets\n",
    "search_response = twitter.search(q='#NFL', count=1000)\n",
    "len(search_response['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f088",
   "metadata": {},
   "source": [
    "In order to get more tweets from a search, we can make use of a cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 1000\n",
    "\n",
    "cursor = twitter.cursor(twitter.search, q='#NFL', count=100, result_type='mixed')\n",
    "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2a503",
   "metadata": {},
   "source": [
    "# 5.0 Creating Twitter mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35657e86",
   "metadata": {},
   "source": [
    "- Aqui come√ßa a an√°lise dos dados coletados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4fc7",
   "metadata": {},
   "source": [
    "- A rede ser√° criada de acordo com os steets que possuem o conte√∫do \"NFL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bd57f",
   "metadata": {},
   "source": [
    "- Ser√° an√°lisado os usu√°rios mais citados dentro do contexto NFL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55152c4",
   "metadata": {},
   "source": [
    "## 5.1 Get some tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e6ae2",
   "metadata": {},
   "source": [
    "- Limit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "22e67d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1645217222}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154356f",
   "metadata": {},
   "source": [
    "- Para extrapolar o uso da API, iremos usar a fun√ß√£o \"sleep\", para usar as 180 requisi√ß√µes a cada 15 minutos, extraindo assim o m√°ximo de tweets em um curto intervalo de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4afe8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import time \n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 17900\n",
    "limit = 0\n",
    "\n",
    "while limit < 5:\n",
    "    cursor = twitter.cursor(twitter.search, q='NFL', count=100, result_type='mixed')\n",
    "    search_tweets += list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "    limit += 1\n",
    "    time.sleep(900) #Dormir por 15 minutos\n",
    "    \n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b8f5f7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d674b4",
   "metadata": {},
   "source": [
    "- Aqui os tweets est√£o em formato de lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4c4fa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2f6b0",
   "metadata": {},
   "source": [
    "- Na c√©lula abaixo, iremos filtra apenas os itens que nos interessa, e transforma a lista em um dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "86084f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'location':[], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['location'].append(tweet['user']['location'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "be8ac6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf0383",
   "metadata": {},
   "source": [
    "## 5.2 Baixando o Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24451cc",
   "metadata": {},
   "source": [
    "- Fazendo o download do dataset por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "968029dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"day7.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e5eec",
   "metadata": {},
   "source": [
    "- Salvano dados separadamente, por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5791e6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e4b6e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7f7ae770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f3d1096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bf2f0af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "286e6ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a33afb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "41eb7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal = pd.concat([day1, day2, day3, day4, day5, day6, day7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "77b280b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626500, 5)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "37944f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"dftotal.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85d586",
   "metadata": {},
   "source": [
    "## 5.3 Creating DiGraph \n",
    "It's not necessary to first filter out tweets containing user mentions due to a feature of Tweet Objects: every tweet has Entities which always contains a 'user_mentions' list, even if that list is empty. Since a tweet may mention more than one user, we need a nested for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d40b486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    tweet_sn = tweet['user']['screen_name']\n",
    "    for user_mention in tweet['entities']['user_mentions']:\n",
    "        mentioned_sn = user_mention['screen_name']\n",
    "        \n",
    "        my_edge = (tweet_sn, mentioned_sn)\n",
    "        if D.has_edge(*my_edge):\n",
    "            D.edges[my_edge]['weight'] += 1\n",
    "        else:\n",
    "            D.add_edge(*my_edge, weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca7bba",
   "metadata": {},
   "source": [
    "# 5.4 Analyze graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d466d",
   "metadata": {},
   "source": [
    "## 5.4.1 Most popular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f9034cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NFL'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(D.nodes, key=D.in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b9acc238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NFL', 9797),\n",
       " ('RamsNFL', 2746),\n",
       " ('TomBrady', 1685),\n",
       " ('NFLFilms', 1289),\n",
       " ('brgridiron', 1043)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted(D.in_degree(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea642e",
   "metadata": {},
   "source": [
    "## 5.4.2 Conversation drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "156a235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PrinceodbRuiz', 1610),\n",
       " ('JoeShow68347212', 942),\n",
       " ('GgBob52440552', 700),\n",
       " ('TyronMiller7', 672),\n",
       " ('eazeee2004', 502)]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(D.out_degree(weight='weight'), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9febb",
   "metadata": {},
   "source": [
    "## 5.4.3 Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5a16ca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "eeede7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3128"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_weakly_connected_components(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31d744",
   "metadata": {},
   "source": [
    "## 5.4.4 Extraindo o componente gigante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0e62834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "29716deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                user   date   text  favorite_count\n",
      "location                                                          \n",
      "                               31280  31280  31280           31280\n",
      "                                   6      6      6               6\n",
      "   Madison, IN.                    1      1      1               1\n",
      " 20.11.02.02                       5      5      5               5\n",
      " Blogging About Football           5      5      5               5\n",
      "...                              ...    ...    ...             ...\n",
      "ü§∫                                  5      5      5               5\n",
      "ü•µü•∂Salvador                         5      5      5               5\n",
      "ü•∑                                  5      5      5               5\n",
      "ü¶§                                  5      5      5               5\n",
      "ü™ê                                  5      5      5               5\n",
      "\n",
      "[5012 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "freq = day1.groupby(['location']).count() \n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b26b88",
   "metadata": {},
   "source": [
    "## 5.4.5 Eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "4e372512",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.eccentricity(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc648507",
   "metadata": {},
   "source": [
    "## 5.4.6 Diameter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c019d6",
   "metadata": {},
   "source": [
    "## 5.4.7 Pepiphery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796fa89a",
   "metadata": {},
   "source": [
    "## 5.4.8 Radius "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e57c9",
   "metadata": {},
   "source": [
    "## 5.4.9 Center  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a39737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
