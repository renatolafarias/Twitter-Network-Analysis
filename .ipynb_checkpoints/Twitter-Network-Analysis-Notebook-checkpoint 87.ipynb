{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f0851",
   "metadata": {},
   "source": [
    "# 1.0 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd60eb04",
   "metadata": {},
   "source": [
    "# 2.0 Authenticating with Twitter's API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7058aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from Twython) (2.25.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, Twython\n",
      "Successfully installed Twython-3.9.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd422936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "43be9cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decorator==5.0.9\n",
      "  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: decorator\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.6\n",
      "    Uninstalling decorator-5.0.6:\n",
      "      Successfully uninstalled decorator-5.0.6\n",
      "Successfully installed decorator-5.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc89aa",
   "metadata": {},
   "source": [
    "## 2.1 Enter app info and get auth URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360821",
   "metadata": {},
   "source": [
    "In order to authenticate with Twitter, we'll provide the app details and ask for a one-time authorization URL to authenticate your user with this app.\n",
    "\n",
    "Copy and paste the API key and secret from your Twitter app into a file named keys.txt. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the keys.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load keys.txt\n",
    "GRvkTm3qkMOM8YjyNp3S6xLO4\n",
    "YmHFrSSnC7D1qNUemiDbmtaMvF0saiFzyyW15erffxGCuQyiFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the keys file\n",
    "my_file = open(\"keys.txt\", \"r\")\n",
    "\n",
    "# read the raw data\n",
    "content = my_file.read()\n",
    "\n",
    "# split all lines by  newline character\n",
    "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a7e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authenticate?oauth_token=LPL9XAAAAAABZBP-AAABftrkV8E\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
    "\n",
    "authentication_tokens = twitter.get_authentication_tokens()\n",
    "print(authentication_tokens['auth_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc878",
   "metadata": {},
   "source": [
    "## 2.2 Authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
    "VERIFIER = '3396549'\n",
    "\n",
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authentication_tokens['oauth_token'],\n",
    "                  authentication_tokens['oauth_token_secret'])\n",
    "\n",
    "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d775",
   "metadata": {},
   "source": [
    "## 2.3 Use authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f4db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1486095105811484677,\n",
       " 'id_str': '1486095105811484677',\n",
       " 'name': 'Renato Farias',\n",
       " 'screen_name': 'renatolinsfar',\n",
       " 'location': '',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 9,\n",
       " 'friends_count': 50,\n",
       " 'listed_count': 2,\n",
       " 'created_at': 'Tue Jan 25 21:55:10 +0000 2022',\n",
       " 'favourites_count': 0,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
       " 'statuses_count': 1,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sat Jan 29 01:36:43 +0000 2022',\n",
       "  'id': 1487238244727238656,\n",
       "  'id_str': '1487238244727238656',\n",
       "  'text': 'Olá, eu acabei de publicar no Medium uma matéria sobre meu trabalho de Análise de Redes usando o dataset “Spotify M… https://t.co/UsjSkojKUd',\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/UsjSkojKUd',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1487238244727238656',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'pt'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'F5F8FA',\n",
       " 'profile_background_image_url': None,\n",
       " 'profile_background_image_url_https': None,\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': True,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'withheld_in_countries': [],\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authorized_tokens['oauth_token'],\n",
    "                  authorized_tokens['oauth_token_secret'])\n",
    "\n",
    "twitter.verify_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5bcec",
   "metadata": {},
   "source": [
    "# 3.0 Twitter API basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35e191",
   "metadata": {},
   "source": [
    "We've already seen one User Object, the one corresponding to the logged-in user, via the call to verify_credentials() above. We can also fetch data for an arbitrary user:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ee657",
   "metadata": {},
   "source": [
    "- Acredito que em nosso projeto, não usaremos essa funcionalidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dafc",
   "metadata": {},
   "source": [
    "# 4.0 Using Twitter's search API to get tweets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7bed0",
   "metadata": {},
   "source": [
    "Twitter's Search API allows you to fetch recent tweets according to a query of keywords, URLs, hashtags, user mentions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3572f",
   "metadata": {},
   "source": [
    "## 4.1 Using a cursor to get more than 100 tweets from a search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed954d",
   "metadata": {},
   "source": [
    "## Getting some tweets for create some graph test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b975cf",
   "metadata": {},
   "source": [
    "- Explorando os limites da API na captura de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even with count=1000, we still get at most 100 tweets\n",
    "search_response = twitter.search(q='#NFL', count=1000)\n",
    "len(search_response['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f088",
   "metadata": {},
   "source": [
    "In order to get more tweets from a search, we can make use of a cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 1000\n",
    "\n",
    "cursor = twitter.cursor(twitter.search, q='#NFL', count=100, result_type='mixed')\n",
    "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2a503",
   "metadata": {},
   "source": [
    "# 5.0 Creating Twitter mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35657e86",
   "metadata": {},
   "source": [
    "- Aqui começa a análise dos dados coletados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4fc7",
   "metadata": {},
   "source": [
    "- A rede será criada de acordo com os steets que possuem o conteúdo \"NFL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bd57f",
   "metadata": {},
   "source": [
    "- Será análisado os usuários mais citados dentro do contexto NFL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3463e88",
   "metadata": {},
   "source": [
    "## 5.1 Get some tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb9eb5",
   "metadata": {},
   "source": [
    "- Limit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fc9bec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1645217222}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ccc55d",
   "metadata": {},
   "source": [
    "- Para extrapolar o uso da API, iremos usar a função \"sleep\", para usar as 180 requisições a cada 15 minutos, extraindo assim o máximo de tweets em um curto intervalo de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4afe8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import time \n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 17900\n",
    "limit = 0\n",
    "\n",
    "while limit < 5:\n",
    "    cursor = twitter.cursor(twitter.search, q='NFL', count=100, result_type='mixed')\n",
    "    search_tweets += list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "    limit += 1\n",
    "    time.sleep(900) #Dormir por 15 minutos\n",
    "    \n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f9b33f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e05cfb",
   "metadata": {},
   "source": [
    "- Aqui os tweets estão em formato de lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5048387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809f387",
   "metadata": {},
   "source": [
    "- Na célula abaixo, iremos filtra apenas os itens que nos interessa, e transforma a lista em um dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0f2ff719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'location':[], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['location'].append(tweet['user']['location'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d2839e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bfb5d",
   "metadata": {},
   "source": [
    "## 5.2 Baixando o Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c67e3e",
   "metadata": {},
   "source": [
    "- Fazendo o download do dataset por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "736a905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"day7.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562808f8",
   "metadata": {},
   "source": [
    "- Salvano dados separadamente, por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "249dedbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4f001054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fcae3726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "10931c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "143e0096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "42d8a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a82a969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b1cc7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal = pd.concat([day1, day2, day3, day4, day5, day6, day7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "02101bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626500, 5)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "16534e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"dftotal.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12f3cc",
   "metadata": {},
   "source": [
    "## 5.3 Creating DiGraph \n",
    "It's not necessary to first filter out tweets containing user mentions due to a feature of Tweet Objects: every tweet has Entities which always contains a 'user_mentions' list, even if that list is empty. Since a tweet may mention more than one user, we need a nested for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0ba45db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    tweet_sn = tweet['user']['screen_name']\n",
    "    for user_mention in tweet['entities']['user_mentions']:\n",
    "        mentioned_sn = user_mention['screen_name']\n",
    "        \n",
    "        my_edge = (tweet_sn, mentioned_sn)\n",
    "        if D.has_edge(*my_edge):\n",
    "            D.edges[my_edge]['weight'] += 1\n",
    "        else:\n",
    "            D.add_edge(*my_edge, weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423f71f",
   "metadata": {},
   "source": [
    "# 5.4 Analyze graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27470b",
   "metadata": {},
   "source": [
    "## 5.4.1 Most popular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d27f878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NFL'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(D.nodes, key=D.in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "24f37228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NFL', 9797),\n",
       " ('RamsNFL', 2746),\n",
       " ('TomBrady', 1685),\n",
       " ('NFLFilms', 1289),\n",
       " ('brgridiron', 1043)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted(D.in_degree(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07dce5",
   "metadata": {},
   "source": [
    "## 5.4.2 Conversation drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3c14f5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PrinceodbRuiz', 1610),\n",
       " ('JoeShow68347212', 942),\n",
       " ('GgBob52440552', 700),\n",
       " ('TyronMiller7', 672),\n",
       " ('eazeee2004', 502)]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(D.out_degree(weight='weight'), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ed27e",
   "metadata": {},
   "source": [
    "## 5.4.3 Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4e91e457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d6dbccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3128"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_weakly_connected_components(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70d169",
   "metadata": {},
   "source": [
    "## 5.4.4 Extraindo o componente gigante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3356990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "38dd4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "                     220740\n",
      "\\n                        1\n",
      "                         58\n",
      "                         13\n",
      "                          6\n",
      "                      ...  \n",
      "🪐                        39\n",
      "🪐, w notis                2\n",
      "🪐. . . #갓세븐 #더보이즈         4\n",
      "🪐BASEDWORLD🪐              3\n",
      "🪐she/her🦇                 2\n",
      "Name: user, Length: 39579, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "freq = dftotal.groupby(['location'])[\"user\"].count() \n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc6164",
   "metadata": {},
   "source": [
    "## 5.4.5 Eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b00eae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.eccentricity(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6645c3",
   "metadata": {},
   "source": [
    "## 5.4.6 Diameter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa707319",
   "metadata": {},
   "source": [
    "## 5.4.7 Pepiphery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d053318",
   "metadata": {},
   "source": [
    "## 5.4.8 Radius "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c901d103",
   "metadata": {},
   "source": [
    "## 5.4.9 Center  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa0125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
