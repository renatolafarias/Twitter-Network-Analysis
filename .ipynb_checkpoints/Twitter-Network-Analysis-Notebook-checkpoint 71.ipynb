{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f0851",
   "metadata": {},
   "source": [
    "# 1.0 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd60eb04",
   "metadata": {},
   "source": [
    "# 2.0 Authenticating with Twitter's API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7058aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from Twython) (2.25.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, Twython\n",
      "Successfully installed Twython-3.9.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd422936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc89aa",
   "metadata": {},
   "source": [
    "## 2.1 Enter app info and get auth URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360821",
   "metadata": {},
   "source": [
    "In order to authenticate with Twitter, we'll provide the app details and ask for a one-time authorization URL to authenticate your user with this app.\n",
    "\n",
    "Copy and paste the API key and secret from your Twitter app into a file named keys.txt. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the keys.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load keys.txt\n",
    "GRvkTm3qkMOM8YjyNp3S6xLO4\n",
    "YmHFrSSnC7D1qNUemiDbmtaMvF0saiFzyyW15erffxGCuQyiFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the keys file\n",
    "my_file = open(\"keys.txt\", \"r\")\n",
    "\n",
    "# read the raw data\n",
    "content = my_file.read()\n",
    "\n",
    "# split all lines by  newline character\n",
    "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a7e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authenticate?oauth_token=LPL9XAAAAAABZBP-AAABftrkV8E\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
    "\n",
    "authentication_tokens = twitter.get_authentication_tokens()\n",
    "print(authentication_tokens['auth_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc878",
   "metadata": {},
   "source": [
    "## 2.2 Authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
    "VERIFIER = '3396549'\n",
    "\n",
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authentication_tokens['oauth_token'],\n",
    "                  authentication_tokens['oauth_token_secret'])\n",
    "\n",
    "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d775",
   "metadata": {},
   "source": [
    "## 2.3 Use authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f4db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1486095105811484677,\n",
       " 'id_str': '1486095105811484677',\n",
       " 'name': 'Renato Farias',\n",
       " 'screen_name': 'renatolinsfar',\n",
       " 'location': '',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 9,\n",
       " 'friends_count': 50,\n",
       " 'listed_count': 2,\n",
       " 'created_at': 'Tue Jan 25 21:55:10 +0000 2022',\n",
       " 'favourites_count': 0,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
       " 'statuses_count': 1,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sat Jan 29 01:36:43 +0000 2022',\n",
       "  'id': 1487238244727238656,\n",
       "  'id_str': '1487238244727238656',\n",
       "  'text': 'Olá, eu acabei de publicar no Medium uma matéria sobre meu trabalho de Análise de Redes usando o dataset “Spotify M… https://t.co/UsjSkojKUd',\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/UsjSkojKUd',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1487238244727238656',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'pt'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'F5F8FA',\n",
       " 'profile_background_image_url': None,\n",
       " 'profile_background_image_url_https': None,\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': True,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'withheld_in_countries': [],\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authorized_tokens['oauth_token'],\n",
    "                  authorized_tokens['oauth_token_secret'])\n",
    "\n",
    "twitter.verify_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5bcec",
   "metadata": {},
   "source": [
    "# 3.0 Twitter API basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35e191",
   "metadata": {},
   "source": [
    "We've already seen one User Object, the one corresponding to the logged-in user, via the call to verify_credentials() above. We can also fetch data for an arbitrary user:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ee657",
   "metadata": {},
   "source": [
    "- Acredito que em nosso projeto, não usaremos essa funcionalidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dafc",
   "metadata": {},
   "source": [
    "# 4.0 Using Twitter's search API to get tweets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7bed0",
   "metadata": {},
   "source": [
    "Twitter's Search API allows you to fetch recent tweets according to a query of keywords, URLs, hashtags, user mentions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3572f",
   "metadata": {},
   "source": [
    "## 4.1 Using a cursor to get more than 100 tweets from a search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7ed5e",
   "metadata": {},
   "source": [
    "## Getting some tweets for create some graph test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b975cf",
   "metadata": {},
   "source": [
    "- Explorando os limites da API na captura de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even with count=1000, we still get at most 100 tweets\n",
    "search_response = twitter.search(q='#NFL', count=1000)\n",
    "len(search_response['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f088",
   "metadata": {},
   "source": [
    "In order to get more tweets from a search, we can make use of a cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 1000\n",
    "\n",
    "cursor = twitter.cursor(twitter.search, q='#NFL', count=100, result_type='mixed')\n",
    "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2a503",
   "metadata": {},
   "source": [
    "# 5.0 Creating Twitter mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35657e86",
   "metadata": {},
   "source": [
    "- Aqui começa a análise dos dados coletados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4fc7",
   "metadata": {},
   "source": [
    "- A rede será criada de acordo com os steets que possuem o conteúdo \"NFL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bd57f",
   "metadata": {},
   "source": [
    "- Será análisado os usuários mais citados dentro do contexto NFL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbca26b",
   "metadata": {},
   "source": [
    "## 5.1 Get some tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45defd40",
   "metadata": {},
   "source": [
    "- Limit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9c62f708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1645217222}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff35f5",
   "metadata": {},
   "source": [
    "- Para extrapolar o uso da API, iremos usar a função \"sleep\", para usar as 180 requisições a cada 15 minutos, extraindo assim o máximo de tweets em um curto intervalo de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4afe8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import time \n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 17900\n",
    "limit = 0\n",
    "\n",
    "while limit < 5:\n",
    "    cursor = twitter.cursor(twitter.search, q='NFL', count=100, result_type='mixed')\n",
    "    search_tweets += list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "    limit += 1\n",
    "    time.sleep(900) #Dormir por 15 minutos\n",
    "    \n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "7376a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55f27d",
   "metadata": {},
   "source": [
    "- Aqui os tweets estão em formato de lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d3b5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205d5da",
   "metadata": {},
   "source": [
    "- Na célula abaixo, iremos filtra apenas os itens que nos interessa, e transforma a lista em um dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "657094c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'location':[], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['location'].append(tweet['user']['location'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e7001007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb2804",
   "metadata": {},
   "source": [
    "## 5.2 Baixando o Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d6e63",
   "metadata": {},
   "source": [
    "- Fazendo o download do dataset por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d976e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"day7.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d1f22",
   "metadata": {},
   "source": [
    "- Salvano dados separadamente, por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "289d861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BleacherReport</td>\n",
       "      <td>Wed Feb 16 01:02:04 +0000 2022</td>\n",
       "      <td>The moment Van Jefferson found out his wife wa...</td>\n",
       "      <td></td>\n",
       "      <td>69799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TomBrady</td>\n",
       "      <td>Wed Feb 16 20:11:27 +0000 2022</td>\n",
       "      <td>Mix in a water Matt…trust me https://t.co/WEVu...</td>\n",
       "      <td></td>\n",
       "      <td>215360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplexSports</td>\n",
       "      <td>Tue Feb 15 23:35:31 +0000 2022</td>\n",
       "      <td>“Van, Van! Your wife is giving birth right now...</td>\n",
       "      <td></td>\n",
       "      <td>46931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DisguiseDevilin</td>\n",
       "      <td>Thu Feb 17 00:02:28 +0000 2022</td>\n",
       "      <td>#NFL   #LorettaLynch https://t.co/MeuHTZ7cD8</td>\n",
       "      <td>Terre/Earth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sandsyyy</td>\n",
       "      <td>Thu Feb 17 00:02:27 +0000 2022</td>\n",
       "      <td>#Raidernation https://t.co/IzIxvwY9Vs</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89495</th>\n",
       "      <td>Ian39864754</td>\n",
       "      <td>Tue Feb 15 20:49:23 +0000 2022</td>\n",
       "      <td>@Dan_KP Why would Levy want players who win ev...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89496</th>\n",
       "      <td>tjens71</td>\n",
       "      <td>Tue Feb 15 20:49:23 +0000 2022</td>\n",
       "      <td>RT @RapSheet: The NFL watched all of Eminem’s ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89497</th>\n",
       "      <td>Buffy619</td>\n",
       "      <td>Tue Feb 15 20:49:23 +0000 2022</td>\n",
       "      <td>RT @j_Borders: @HeatleyJared The 4 game stretc...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89498</th>\n",
       "      <td>jacobswartz3</td>\n",
       "      <td>Tue Feb 15 20:49:22 +0000 2022</td>\n",
       "      <td>RT @RapSheet: The NFL watched all of Eminem’s ...</td>\n",
       "      <td>Piqua, OH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89499</th>\n",
       "      <td>_tremoney34</td>\n",
       "      <td>Tue Feb 15 20:49:22 +0000 2022</td>\n",
       "      <td>@SamHoweII @NFL_Memes You French?</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user                            date  \\\n",
       "0       BleacherReport  Wed Feb 16 01:02:04 +0000 2022   \n",
       "1             TomBrady  Wed Feb 16 20:11:27 +0000 2022   \n",
       "2        ComplexSports  Tue Feb 15 23:35:31 +0000 2022   \n",
       "3      DisguiseDevilin  Thu Feb 17 00:02:28 +0000 2022   \n",
       "4             sandsyyy  Thu Feb 17 00:02:27 +0000 2022   \n",
       "...                ...                             ...   \n",
       "89495      Ian39864754  Tue Feb 15 20:49:23 +0000 2022   \n",
       "89496          tjens71  Tue Feb 15 20:49:23 +0000 2022   \n",
       "89497         Buffy619  Tue Feb 15 20:49:23 +0000 2022   \n",
       "89498     jacobswartz3  Tue Feb 15 20:49:22 +0000 2022   \n",
       "89499      _tremoney34  Tue Feb 15 20:49:22 +0000 2022   \n",
       "\n",
       "                                                    text     location  \\\n",
       "0      The moment Van Jefferson found out his wife wa...                \n",
       "1      Mix in a water Matt…trust me https://t.co/WEVu...                \n",
       "2      “Van, Van! Your wife is giving birth right now...                \n",
       "3           #NFL   #LorettaLynch https://t.co/MeuHTZ7cD8  Terre/Earth   \n",
       "4                  #Raidernation https://t.co/IzIxvwY9Vs                \n",
       "...                                                  ...          ...   \n",
       "89495  @Dan_KP Why would Levy want players who win ev...                \n",
       "89496  RT @RapSheet: The NFL watched all of Eminem’s ...                \n",
       "89497  RT @j_Borders: @HeatleyJared The 4 game stretc...                \n",
       "89498  RT @RapSheet: The NFL watched all of Eminem’s ...    Piqua, OH   \n",
       "89499                  @SamHoweII @NFL_Memes You French?                \n",
       "\n",
       "       favorite_count  \n",
       "0               69799  \n",
       "1              215360  \n",
       "2               46931  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "89495               0  \n",
       "89496               0  \n",
       "89497               0  \n",
       "89498               0  \n",
       "89499               1  \n",
       "\n",
       "[89500 rows x 5 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0827dc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3b6b2123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d8d355c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "de37bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0eac656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8acf37ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290aba3",
   "metadata": {},
   "source": [
    "## 5.3 Creating DiGraph \n",
    "It's not necessary to first filter out tweets containing user mentions due to a feature of Tweet Objects: every tweet has Entities which always contains a 'user_mentions' list, even if that list is empty. Since a tweet may mention more than one user, we need a nested for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "669716af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    tweet_sn = tweet['user']['screen_name']\n",
    "    for user_mention in tweet['entities']['user_mentions']:\n",
    "        mentioned_sn = user_mention['screen_name']\n",
    "        \n",
    "        my_edge = (tweet_sn, mentioned_sn)\n",
    "        if D.has_edge(*my_edge):\n",
    "            D.edges[my_edge]['weight'] += 1\n",
    "        else:\n",
    "            D.add_edge(*my_edge, weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337a30b",
   "metadata": {},
   "source": [
    "# 5.4 Analyze graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736f224",
   "metadata": {},
   "source": [
    "## 5.4.1 Most popular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b6afdb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NFL'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(D.nodes, key=D.in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c65e0277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NFL', 9797),\n",
       " ('RamsNFL', 2746),\n",
       " ('TomBrady', 1685),\n",
       " ('NFLFilms', 1289),\n",
       " ('brgridiron', 1043)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted(D.in_degree(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb08385",
   "metadata": {},
   "source": [
    "## 5.4.2 Conversation drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b0c04282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PrinceodbRuiz', 1610),\n",
       " ('JoeShow68347212', 942),\n",
       " ('GgBob52440552', 700),\n",
       " ('TyronMiller7', 672),\n",
       " ('eazeee2004', 502)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(D.out_degree(weight='weight'), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf43b83",
   "metadata": {},
   "source": [
    "## 5.4.3 Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8a09f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1d708c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3128"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_weakly_connected_components(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c845c8d",
   "metadata": {},
   "source": [
    "## 5.4.4 Extraindo o componente gigante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7799ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.remove_edges_from(list(nx.selfloop_edges(D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1b2112ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6281c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
