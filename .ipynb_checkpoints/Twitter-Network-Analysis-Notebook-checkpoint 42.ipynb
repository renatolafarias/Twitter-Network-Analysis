{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f0851",
   "metadata": {},
   "source": [
    "# 1.0 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd60eb04",
   "metadata": {},
   "source": [
    "# 2.0 Authenticating with Twitter's API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7058aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from Twython) (2.25.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, Twython\n",
      "Successfully installed Twython-3.9.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd422936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc89aa",
   "metadata": {},
   "source": [
    "## 2.1 Enter app info and get auth URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360821",
   "metadata": {},
   "source": [
    "In order to authenticate with Twitter, we'll provide the app details and ask for a one-time authorization URL to authenticate your user with this app.\n",
    "\n",
    "Copy and paste the API key and secret from your Twitter app into a file named keys.txt. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the keys.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load keys.txt\n",
    "GRvkTm3qkMOM8YjyNp3S6xLO4\n",
    "YmHFrSSnC7D1qNUemiDbmtaMvF0saiFzyyW15erffxGCuQyiFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the keys file\n",
    "my_file = open(\"keys.txt\", \"r\")\n",
    "\n",
    "# read the raw data\n",
    "content = my_file.read()\n",
    "\n",
    "# split all lines by  newline character\n",
    "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a7e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authenticate?oauth_token=LPL9XAAAAAABZBP-AAABftrkV8E\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
    "\n",
    "authentication_tokens = twitter.get_authentication_tokens()\n",
    "print(authentication_tokens['auth_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc878",
   "metadata": {},
   "source": [
    "## 2.2 Authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
    "VERIFIER = '3396549'\n",
    "\n",
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authentication_tokens['oauth_token'],\n",
    "                  authentication_tokens['oauth_token_secret'])\n",
    "\n",
    "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d775",
   "metadata": {},
   "source": [
    "## 2.3 Use authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f4db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1486095105811484677,\n",
       " 'id_str': '1486095105811484677',\n",
       " 'name': 'Renato Farias',\n",
       " 'screen_name': 'renatolinsfar',\n",
       " 'location': '',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 9,\n",
       " 'friends_count': 50,\n",
       " 'listed_count': 2,\n",
       " 'created_at': 'Tue Jan 25 21:55:10 +0000 2022',\n",
       " 'favourites_count': 0,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
       " 'statuses_count': 1,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sat Jan 29 01:36:43 +0000 2022',\n",
       "  'id': 1487238244727238656,\n",
       "  'id_str': '1487238244727238656',\n",
       "  'text': 'Olá, eu acabei de publicar no Medium uma matéria sobre meu trabalho de Análise de Redes usando o dataset “Spotify M… https://t.co/UsjSkojKUd',\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/UsjSkojKUd',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1487238244727238656',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'pt'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'F5F8FA',\n",
       " 'profile_background_image_url': None,\n",
       " 'profile_background_image_url_https': None,\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': True,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'withheld_in_countries': [],\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authorized_tokens['oauth_token'],\n",
    "                  authorized_tokens['oauth_token_secret'])\n",
    "\n",
    "twitter.verify_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5bcec",
   "metadata": {},
   "source": [
    "# 3.0 Twitter API basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35e191",
   "metadata": {},
   "source": [
    "We've already seen one User Object, the one corresponding to the logged-in user, via the call to verify_credentials() above. We can also fetch data for an arbitrary user:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ee657",
   "metadata": {},
   "source": [
    "- Acredito que em nosso projeto, não usaremos essa funcionalidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dafc",
   "metadata": {},
   "source": [
    "# 4.0 Using Twitter's search API to get tweets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7bed0",
   "metadata": {},
   "source": [
    "Twitter's Search API allows you to fetch recent tweets according to a query of keywords, URLs, hashtags, user mentions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3572f",
   "metadata": {},
   "source": [
    "## 4.1 Using a cursor to get more than 100 tweets from a search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc19a39",
   "metadata": {},
   "source": [
    "## Getting some tweets for create some graph test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b975cf",
   "metadata": {},
   "source": [
    "- Explorando os limites da API na captura de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even with count=1000, we still get at most 100 tweets\n",
    "search_response = twitter.search(q='#NFL', count=1000)\n",
    "len(search_response['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f088",
   "metadata": {},
   "source": [
    "In order to get more tweets from a search, we can make use of a cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 1000\n",
    "\n",
    "cursor = twitter.cursor(twitter.search, q='#NFL', count=100, result_type='mixed')\n",
    "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2a503",
   "metadata": {},
   "source": [
    "# 5.0 Creating Twitter mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35657e86",
   "metadata": {},
   "source": [
    "- Aqui começa a análise dos dados coletados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4fc7",
   "metadata": {},
   "source": [
    "- A rede será criada de acordo com os steets que possuem o conteúdo \"NFL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bd57f",
   "metadata": {},
   "source": [
    "- Será análisado os usuários mais citados dentro do contexto NFL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbf132",
   "metadata": {},
   "source": [
    "## 5.1 Get some tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86843c5",
   "metadata": {},
   "source": [
    "- Limit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7cef828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1644798622}}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c5681",
   "metadata": {},
   "source": [
    "- Para extrapolar o uso da API, iremos usar a função \"sleep\", para usar as 180 requisições a cada 15 minutos, extraindo assim o máximo de tweets em um curto intervalo de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time \n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 17900\n",
    "limit = 0\n",
    "\n",
    "while limit < 5:\n",
    "    cursor = twitter.cursor(twitter.search, q='NFL', count=100, result_type='mixed')\n",
    "    search_tweets += list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "    limit += 1\n",
    "    time.sleep(910) #Dormir por 15 minutos\n",
    "    \n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6424eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tweets.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c718d331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4f6ae",
   "metadata": {},
   "source": [
    "- Aqui os tweets estão em formato de lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "05fb4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8f6bf",
   "metadata": {},
   "source": [
    "- Na célula abaixo, iremos filtra apenas os itens que nos interessa, e transforma a lista em um dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c4ea89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'location':[], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['location'].append(tweet['user']['location'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5bfac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdamSchefter</td>\n",
       "      <td>Wed Feb 09 22:20:33 +0000 2022</td>\n",
       "      <td>ESPN expanded its agreement with Peyton and El...</td>\n",
       "      <td>New York</td>\n",
       "      <td>48236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChrisVannini</td>\n",
       "      <td>Wed Feb 09 16:31:52 +0000 2022</td>\n",
       "      <td>Petition to bring back fun Super Bowl logos. \\...</td>\n",
       "      <td>Dallas (imported from Detroit)</td>\n",
       "      <td>24427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JimTrotter_NFL</td>\n",
       "      <td>Wed Feb 09 21:10:48 +0000 2022</td>\n",
       "      <td>The NFL says diversity, equity and inclusion a...</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Og_Django</td>\n",
       "      <td>Thu Feb 10 17:56:50 +0000 2022</td>\n",
       "      <td>@NFL @NFLALLDAY Jamar chase</td>\n",
       "      <td>florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goatedshit</td>\n",
       "      <td>Thu Feb 10 17:56:49 +0000 2022</td>\n",
       "      <td>@brgridiron @NFL @NFLFilms Bills gonna punish ...</td>\n",
       "      <td>Top of the buildin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                            date  \\\n",
       "0    AdamSchefter  Wed Feb 09 22:20:33 +0000 2022   \n",
       "1    ChrisVannini  Wed Feb 09 16:31:52 +0000 2022   \n",
       "2  JimTrotter_NFL  Wed Feb 09 21:10:48 +0000 2022   \n",
       "3       Og_Django  Thu Feb 10 17:56:50 +0000 2022   \n",
       "4      goatedshit  Thu Feb 10 17:56:49 +0000 2022   \n",
       "\n",
       "                                                text  \\\n",
       "0  ESPN expanded its agreement with Peyton and El...   \n",
       "1  Petition to bring back fun Super Bowl logos. \\...   \n",
       "2  The NFL says diversity, equity and inclusion a...   \n",
       "3                        @NFL @NFLALLDAY Jamar chase   \n",
       "4  @brgridiron @NFL @NFLFilms Bills gonna punish ...   \n",
       "\n",
       "                         location  favorite_count  \n",
       "0                        New York           48236  \n",
       "1  Dallas (imported from Detroit)           24427  \n",
       "2                   San Diego, CA           10009  \n",
       "3                         florida               0  \n",
       "4              Top of the buildin               0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c08f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372e3c0",
   "metadata": {},
   "source": [
    "## 5.2 Baixando o Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d63971",
   "metadata": {},
   "source": [
    "- Fazendo o download do dataset por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0133a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"day3.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ef902",
   "metadata": {},
   "source": [
    "- Salvano dados separadamente, por dia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc826e3",
   "metadata": {},
   "source": [
    "- Day3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a9a5d058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7970efa",
   "metadata": {},
   "source": [
    "- Day2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cd4111f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3a579",
   "metadata": {},
   "source": [
    "- Day1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a5d2a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a25a3",
   "metadata": {},
   "source": [
    "## 5.3 Creating DiGraph \n",
    "It's not necessary to first filter out tweets containing user mentions due to a feature of Tweet Objects: every tweet has Entities which always contains a 'user_mentions' list, even if that list is empty. Since a tweet may mention more than one user, we need a nested for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84450f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    tweet_sn = tweet['user']['screen_name']\n",
    "    for user_mention in tweet['entities']['user_mentions']:\n",
    "        mentioned_sn = user_mention['screen_name']\n",
    "        \n",
    "        my_edge = (tweet_sn, mentioned_sn)\n",
    "        if D.has_edge(*my_edge):\n",
    "            D.edges[my_edge]['weight'] += 1\n",
    "        else:\n",
    "            D.add_edge(*my_edge, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d846f86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
