{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f0851",
   "metadata": {},
   "source": [
    "# 1.0 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd60eb04",
   "metadata": {},
   "source": [
    "# 2.0 Authenticating with Twitter's API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7058aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from Twython) (2.25.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/renatofarias/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.1.0->Twython) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, Twython\n",
      "Successfully installed Twython-3.9.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd422936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d60f4de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decorator==5.0.9\n",
      "  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: decorator\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.6\n",
      "    Uninstalling decorator-5.0.6:\n",
      "      Successfully uninstalled decorator-5.0.6\n",
      "Successfully installed decorator-5.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc89aa",
   "metadata": {},
   "source": [
    "## 2.1 Enter app info and get auth URL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360821",
   "metadata": {},
   "source": [
    "In order to authenticate with Twitter, we'll provide the app details and ask for a one-time authorization URL to authenticate your user with this app.\n",
    "\n",
    "Copy and paste the API key and secret from your Twitter app into a file named keys.txt. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the keys.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load keys.txt\n",
    "GRvkTm3qkMOM8YjyNp3S6xLO4\n",
    "YmHFrSSnC7D1qNUemiDbmtaMvF0saiFzyyW15erffxGCuQyiFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the keys file\n",
    "my_file = open(\"keys.txt\", \"r\")\n",
    "\n",
    "# read the raw data\n",
    "content = my_file.read()\n",
    "\n",
    "# split all lines by  newline character\n",
    "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a7e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authenticate?oauth_token=LPL9XAAAAAABZBP-AAABftrkV8E\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
    "\n",
    "authentication_tokens = twitter.get_authentication_tokens()\n",
    "print(authentication_tokens['auth_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc878",
   "metadata": {},
   "source": [
    "## 2.2 Authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
    "VERIFIER = '3396549'\n",
    "\n",
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authentication_tokens['oauth_token'],\n",
    "                  authentication_tokens['oauth_token_secret'])\n",
    "\n",
    "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d775",
   "metadata": {},
   "source": [
    "## 2.3 Use authorized tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f4db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1486095105811484677,\n",
       " 'id_str': '1486095105811484677',\n",
       " 'name': 'Renato Farias',\n",
       " 'screen_name': 'renatolinsfar',\n",
       " 'location': '',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 9,\n",
       " 'friends_count': 50,\n",
       " 'listed_count': 2,\n",
       " 'created_at': 'Tue Jan 25 21:55:10 +0000 2022',\n",
       " 'favourites_count': 0,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'verified': False,\n",
       " 'statuses_count': 1,\n",
       " 'lang': None,\n",
       " 'status': {'created_at': 'Sat Jan 29 01:36:43 +0000 2022',\n",
       "  'id': 1487238244727238656,\n",
       "  'id_str': '1487238244727238656',\n",
       "  'text': 'Olá, eu acabei de publicar no Medium uma matéria sobre meu trabalho de Análise de Redes usando o dataset “Spotify M… https://t.co/UsjSkojKUd',\n",
       "  'truncated': True,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/UsjSkojKUd',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1487238244727238656',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}]},\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 0,\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'pt'},\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'F5F8FA',\n",
       " 'profile_background_image_url': None,\n",
       " 'profile_background_image_url_https': None,\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1486095326981275650/YBBkc1Ua_normal.jpg',\n",
       " 'profile_link_color': '1DA1F2',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': True,\n",
       " 'default_profile': True,\n",
       " 'default_profile_image': False,\n",
       " 'following': False,\n",
       " 'follow_request_sent': False,\n",
       " 'notifications': False,\n",
       " 'translator_type': 'none',\n",
       " 'withheld_in_countries': [],\n",
       " 'suspended': False,\n",
       " 'needs_phone_verification': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
    "                  authorized_tokens['oauth_token'],\n",
    "                  authorized_tokens['oauth_token_secret'])\n",
    "\n",
    "twitter.verify_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5bcec",
   "metadata": {},
   "source": [
    "# 3.0 Twitter API basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35e191",
   "metadata": {},
   "source": [
    "We've already seen one User Object, the one corresponding to the logged-in user, via the call to verify_credentials() above. We can also fetch data for an arbitrary user:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ee657",
   "metadata": {},
   "source": [
    "- Acredito que em nosso projeto, não usaremos essa funcionalidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dafc",
   "metadata": {},
   "source": [
    "# 4.0 Using Twitter's search API to get tweets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7bed0",
   "metadata": {},
   "source": [
    "Twitter's Search API allows you to fetch recent tweets according to a query of keywords, URLs, hashtags, user mentions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3572f",
   "metadata": {},
   "source": [
    "## 4.1 Using a cursor to get more than 100 tweets from a search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f38cd",
   "metadata": {},
   "source": [
    "## Getting some tweets for create some graph test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b975cf",
   "metadata": {},
   "source": [
    "- Explorando os limites da API na captura de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even with count=1000, we still get at most 100 tweets\n",
    "search_response = twitter.search(q='#NFL', count=1000)\n",
    "len(search_response['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f088",
   "metadata": {},
   "source": [
    "In order to get more tweets from a search, we can make use of a cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 1000\n",
    "\n",
    "cursor = twitter.cursor(twitter.search, q='#NFL', count=100, result_type='mixed')\n",
    "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2a503",
   "metadata": {},
   "source": [
    "# 5.0 Creating Twitter mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35657e86",
   "metadata": {},
   "source": [
    "- Aqui começa a análise dos dados coletados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4fc7",
   "metadata": {},
   "source": [
    "- A rede será criada de acordo com os steets que possuem o conteúdo \"NFL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3bd57f",
   "metadata": {},
   "source": [
    "- Será análisado os usuários mais citados dentro do contexto NFL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95dce9",
   "metadata": {},
   "source": [
    "## 5.1 Get some tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd94e9",
   "metadata": {},
   "source": [
    "- Limit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b5aee371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1645217222}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66264d8",
   "metadata": {},
   "source": [
    "- Para extrapolar o uso da API, iremos usar a função \"sleep\", para usar as 180 requisições a cada 15 minutos, extraindo assim o máximo de tweets em um curto intervalo de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4afe8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import time \n",
    "\n",
    "NUM_TWEETS_TO_FETCH = 17900\n",
    "limit = 0\n",
    "\n",
    "while limit < 5:\n",
    "    cursor = twitter.cursor(twitter.search, q='NFL', count=100, result_type='mixed')\n",
    "    search_tweets += list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
    "    limit += 1\n",
    "    time.sleep(900) #Dormir por 15 minutos\n",
    "    \n",
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "07b19f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304300"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4dccdd",
   "metadata": {},
   "source": [
    "- Aqui os tweets estão em formato de lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08242e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888b229",
   "metadata": {},
   "source": [
    "- Na célula abaixo, iremos filtra apenas os itens que nos interessa, e transforma a lista em um dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "acd4d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'location':[], 'favorite_count': []}\n",
    "for tweet in search_tweets:\n",
    "    dict_['user'].append(tweet['user']['screen_name'])\n",
    "    dict_['date'].append(tweet['created_at'])\n",
    "    dict_['text'].append(tweet['text'])\n",
    "    dict_['location'].append(tweet['user']['location'])\n",
    "    dict_['favorite_count'].append(tweet['favorite_count'])\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "90f5d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ed0a2",
   "metadata": {},
   "source": [
    "## 5.2 Baixando o Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ff037",
   "metadata": {},
   "source": [
    "- Fazendo o download do dataset por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d976c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"day7.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc70e44",
   "metadata": {},
   "source": [
    "- Salvano dados separadamente, por dia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a49f8631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2d6e3114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3c07455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4d467a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2f3110a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6f2adf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7517a4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89500, 5)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b3fbe4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal = pd.concat([day1, day2, day3, day4, day5, day6, day7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "57d8588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626500, 5)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d3f60af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_excel(\"dftotal.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b55014",
   "metadata": {},
   "source": [
    "## 5.3 Creating DiGraph \n",
    "It's not necessary to first filter out tweets containing user mentions due to a feature of Tweet Objects: every tweet has Entities which always contains a 'user_mentions' list, even if that list is empty. Since a tweet may mention more than one user, we need a nested for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "53b26d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "D = nx.DiGraph()\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    tweet_sn = tweet['user']['screen_name']\n",
    "    for user_mention in tweet['entities']['user_mentions']:\n",
    "        mentioned_sn = user_mention['screen_name']\n",
    "        \n",
    "        my_edge = (tweet_sn, mentioned_sn)\n",
    "        if D.has_edge(*my_edge):\n",
    "            D.edges[my_edge]['weight'] += 1\n",
    "        else:\n",
    "            D.add_edge(*my_edge, weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503657ea",
   "metadata": {},
   "source": [
    "# 5.4 Analyze graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81095574",
   "metadata": {},
   "source": [
    "## 5.4.1 Most popular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "38127e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NFL'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(D.nodes, key=D.in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aab3a3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NFL', 9797),\n",
       " ('RamsNFL', 2746),\n",
       " ('TomBrady', 1685),\n",
       " ('NFLFilms', 1289),\n",
       " ('brgridiron', 1043)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted(D.in_degree(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db70ce",
   "metadata": {},
   "source": [
    "## 5.4.2 Conversation drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "babf7733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PrinceodbRuiz', 1610),\n",
       " ('JoeShow68347212', 942),\n",
       " ('GgBob52440552', 700),\n",
       " ('TyronMiller7', 672),\n",
       " ('eazeee2004', 502)]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(D.out_degree(weight='weight'), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee06911",
   "metadata": {},
   "source": [
    "## 5.4.3 Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e5c507dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "82686f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3128"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_weakly_connected_components(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0364eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839d2dc2",
   "metadata": {},
   "source": [
    "## 5.4.4 Locations with the most  NFL Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "dbe220b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = dftotal.groupby(['location'])[\"user\"].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "292bf0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "6403d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = freq.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "f34dff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "                   220740\n",
       "United States        9130\n",
       "Los Angeles, CA      5293\n",
       "Boise, ID            2991\n",
       "Chicago, IL          2945\n",
       "California, USA      2756\n",
       "USA                  2588\n",
       "Houston, TX          2352\n",
       "Florida, USA         2324\n",
       "Atlanta, GA          2275\n",
       "New York, NY         2101\n",
       "Texas, USA           2100\n",
       "Dallas, TX           2091\n",
       "Washington, DC       1954\n",
       "New York, USA        1865\n",
       "New Jersey, USA      1716\n",
       "México               1708\n",
       "Cincinnati, OH       1657\n",
       "Las Vegas, NV        1549\n",
       "Pittsburgh, PA       1541\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f81dd",
   "metadata": {},
   "source": [
    "## 5.4.5 Eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a017a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.eccentricity(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c3f16",
   "metadata": {},
   "source": [
    "## 5.4.6 Diameter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee29ea",
   "metadata": {},
   "source": [
    "## 5.4.7 Pepiphery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383a62f",
   "metadata": {},
   "source": [
    "## 5.4.8 Radius "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eaece0",
   "metadata": {},
   "source": [
    "## 5.4.9 Center  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd9f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
